# A sample state dict for a FLUX DoRA model.
# This format was added in response to https://github.com/invoke-ai/InvokeAI/issues/7131.
# These keys are from https://civitai.com/models/838594/envy-flux-dreamtown-01?modelVersionId=938205.
state_dict_keys = {
    "lora_transformer_single_transformer_blocks_0_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_0_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_0_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_0_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_0_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_0_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_0_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_10_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_10_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_10_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_10_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_10_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_10_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_10_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_11_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_11_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_11_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_11_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_11_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_11_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_11_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_12_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_12_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_12_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_12_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_12_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_12_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_12_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_13_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_13_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_13_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_13_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_13_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_13_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_13_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_14_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_14_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_14_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_14_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_14_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_14_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_14_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_15_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_15_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_15_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_15_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_15_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_15_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_15_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_16_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_16_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_16_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_16_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_16_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_16_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_16_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_17_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_17_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_17_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_17_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_17_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_17_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_17_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_18_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_18_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_18_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_18_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_18_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_18_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_18_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_19_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_19_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_19_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_19_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_19_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_19_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_19_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_1_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_1_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_1_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_1_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_1_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_1_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_1_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_20_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_20_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_20_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_20_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_20_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_20_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_20_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_21_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_21_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_21_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_21_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_21_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_21_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_21_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_22_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_22_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_22_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_22_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_22_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_22_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_22_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_23_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_23_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_23_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_23_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_23_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_23_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_23_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_24_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_24_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_24_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_24_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_24_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_24_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_24_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_25_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_25_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_25_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_25_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_25_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_25_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_25_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_26_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_26_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_26_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_26_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_26_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_26_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_26_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_27_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_27_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_27_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_27_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_27_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_27_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_27_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_28_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_28_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_28_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_28_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_28_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_28_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_28_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_29_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_29_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_29_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_29_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_29_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_29_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_29_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_2_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_2_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_2_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_2_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_2_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_2_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_2_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_30_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_30_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_30_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_30_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_30_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_30_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_30_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_31_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_31_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_31_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_31_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_31_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_31_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_31_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_32_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_32_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_32_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_32_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_32_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_32_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_32_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_33_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_33_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_33_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_33_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_33_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_33_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_33_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_34_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_34_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_34_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_34_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_34_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_34_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_34_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_35_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_35_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_35_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_35_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_35_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_35_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_35_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_36_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_36_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_36_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_36_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_36_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_36_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_36_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_37_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_37_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_37_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_37_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_37_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_37_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_37_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_3_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_3_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_3_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_3_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_3_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_3_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_3_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_4_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_4_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_4_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_4_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_4_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_4_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_4_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_5_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_5_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_5_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_5_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_5_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_5_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_5_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_6_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_6_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_6_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_6_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_6_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_6_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_6_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_7_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_7_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_7_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_7_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_7_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_7_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_7_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_8_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_8_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_8_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_8_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_8_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_8_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_8_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_9_attn_to_k.alpha": [],
    "lora_transformer_single_transformer_blocks_9_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_9_attn_to_q.alpha": [],
    "lora_transformer_single_transformer_blocks_9_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_single_transformer_blocks_9_attn_to_v.alpha": [],
    "lora_transformer_single_transformer_blocks_9_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_single_transformer_blocks_9_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_0_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_0_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_0_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_10_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_10_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_10_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_11_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_11_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_11_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_12_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_12_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_12_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_13_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_13_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_13_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_14_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_14_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_14_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_15_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_15_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_15_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_16_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_16_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_16_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_17_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_17_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_17_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_18_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_18_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_18_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_1_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_1_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_1_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_2_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_2_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_2_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_3_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_3_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_3_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_4_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_4_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_4_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_5_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_5_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_5_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_6_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_6_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_6_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_7_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_7_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_7_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_8_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_8_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_8_attn_to_v.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_add_k_proj.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_add_k_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_k_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_k_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_add_q_proj.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_add_q_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_q_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_q_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_add_v_proj.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_add_v_proj.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_v_proj.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_add_v_proj.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_to_add_out.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_to_add_out.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_add_out.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_add_out.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_to_k.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_to_k.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_k.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_k.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_to_out_0.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_to_out_0.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_out_0.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_out_0.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_to_q.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_to_q.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_q.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_q.lora_up.weight": [3072, 4],
    "lora_transformer_transformer_blocks_9_attn_to_v.alpha": [],
    "lora_transformer_transformer_blocks_9_attn_to_v.dora_scale": [1, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_v.lora_down.weight": [4, 3072],
    "lora_transformer_transformer_blocks_9_attn_to_v.lora_up.weight": [3072, 4],
}
